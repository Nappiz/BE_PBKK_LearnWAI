{"text": "An android based course attendance system using face recognition\nDwi Sunaryonoa, Joko Siswantorob,⇑, Radityo Anggoroa\naDepartment of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indoneisa\nbDepartment of Informatics Engineering, Universitas Surabaya Jl. Kali Rungkut, Surabaya 60293, Indonesia\narticle info\nArticle history:\nReceived 11 September 2018Revised 28 November 2018Accepted 12 January 2019Available online 18 January 2019\nKeywords:\nCourse attendance system\nFace recognition\nAndroid basedSmartphoneabstract\nStudent attendance system is needed to measure student participation in a course. Several automated\nattendance systems have been proposed based on biometric recognition, barcode, QR code, and near ﬁeld\ncommunication mobile device. However, the previous systems are inefﬁcient in term of processing timeand low in accuracy. This paper aims to propose an Android based course attendance system using facerecognition. To ensure the student attend in the course, QR code contained the course information was\ngenerated and displayed at the front of classroom. The student only needed to capture his/her face image\nand displayed QR code using his/her smartphone. The image was then sent to server for attendance pro-cess. The experimental result shows that the proposed attendance system achieved face recognition accu-\nracy of 97.29 by using linear discriminant analysis and only needed 0.000096s to recognize a face image\nin the server./C2112019 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an\nopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).\n1. Introduction\nStudent attendance is an important factor for students to suc-\nceed in a course. In a certain university, stu"}
{"text": "osting by Elsevier B.V. on behalf of King Saud University. This is an\nopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).\n1. Introduction\nStudent attendance is an important factor for students to suc-\nceed in a course. In a certain university, student attendance in a\ncourse is also used as one of requirements for student to take the\nexam ( Islam et al., 2017 ). A conventional approach to record stu-\ndent attendance is performed by asking every student to sign on\nan attendance list that passes through all students during the\nbeginning of lectures. However, this approach is inefﬁcient in term\nof time and can potentially lead to a fraud especially in a large\nclass, where a student can sign on the attendance list for other stu-\ndents who are not present in the class. To avoid the happening of\nfraud, sometimes the lecturer calls out the names of students\nwho have signed on the attendance list one by one. This method\nwill take the lecture time and will have an impact on the effective-\nness of lecture ( Mohamed and Raghu, 2012 ). A modern approach to\nrecord attendance is by using automated attendance system. Sev-\neral automated attendance system have been proposed by employ-ing biometric recognition, such as ﬁngerprint recognition\n(Mohamed and Raghu, 2012; Rao and Satoa, 2013; Soewito et al.,\n2015; Zainal et al., 2016; Zainal et al., 2014 ), face recognition\n(Chintalapati and Raghunadh, 2013; Fuzail et al., 2014; Mehta\nand Tomar, 2016; Raghuwanshi and Swami, 2017; Sayeed et al.,\n2017; Wagh et al., 2015; Wati Mohamad Yusof et al., 2018 ) and\npalm vein recognition ( bayoumi et al., 2015 ) to recognize students\nwho are present and record their attendance. The other proposed\nattendance systems used barcode ( Noor et al., 2015 ),"}
{"text": "2016; Raghuwanshi and Swami, 2017; Sayeed et al.,\n2017; Wagh et al., 2015; Wati Mohamad Yusof et al., 2018 ) and\npalm vein recognition ( bayoumi et al., 2015 ) to recognize students\nwho are present and record their attendance. The other proposed\nattendance systems used barcode ( Noor et al., 2015 ), QR code\n(Rahni et al., 2015 ), RFID ( Arulogun et al., 2013; Bhalla et al.,\n2013; Hussain et al., 2014; Rjeib et al., 2018 ) and near ﬁeld com-\nmunication (NFC) mobile device ( Mohandes, 2017 ) to obtain stu-\ndent ID for attendance process. Some attendance systems were\ndeveloped in portable device ( Mohamed and Raghu, 2012; Zainal\net al., 2016, 2014 ) and smartphone ( Islam, et al., 2017;\nMohandes, 2017; Noor et al., 2015; Rahni et al., 2015; Soewito\net al., 2015 ).\nRao and Satoa (2013) have proposed an employee attendance\nmanagement system using ﬁngerprint recognition. Every check in\nand check out times, employees needed to scan their ﬁngerprint\nto record attendance. Minutiae-based matching combined with\nalignment-based greedy matching was used to recognize scanned\nﬁngerprint in the proposed attendance system. Although the\nauthors reported that the proposed system is easy to use and\nlow cost, the proposed system is not appropriate for course atten-\ndance system since if there are a large number of classes in the\nsame time then the system requires a large number of ﬁngerprint\nrecording devices. Moreover, if there are a large number of stu-\nhttps://doi.org/10.1016/j.jksuci.2019.01.006\n1319-1578/ /C2112019 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.\nThis is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.\nE-mail addresses: dwis@if.its.ac.id (D. Sunaryono"}
{"text": "006\n1319-1578/ /C2112019 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.\nThis is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.\nE-mail addresses: dwis@if.its.ac.id (D. Sunaryono), joko_siswantoro@staff.ubaya.\nac.id (J. Siswantoro), onggo@if.its.ac.id (R. Anggoro).\nPeer review under responsibility of King Saud University.\nProduction and hosting by ElsevierJournal of King Saud University – Computer and Information Sciences 33 (2021) 304–312\nContents lists available at ScienceDirect\nJournal of King Saud University –\nComputer and Information Sciences\njournal homepage: ww w.sciencedirect.com\n\ndents in a course, then the system will cause a long and time con-\nsuming queue. Rao and Satoa (2013), Zainal et al. (2016, 2014)\nhave proposed a portable device for student attendance system\nbased on ﬁngerprint recognition. The proposed systems asked stu-\ndent to scan his/her ﬁngerprint to the device for attendance pro-\ncess. The attendance data was only stored on the device. The\ndevice was not directly connected to the server, as consequent\nthe lecturer needs to back up the data to the server manually after\nclass hour. In addition, many devices are needed if there are many\nclasses at the same time. Soewito, et al. (2015) has proposed an\nemployee attendance system on Android smartphone using ﬁnger-\nprint and GPS integrated with payment system. From the user\nsmartphone, the system recorded ﬁngerprint, attendance time,\nand the coordinate of position trough GPS that available on the\nsmartphone to avoid a long queue and fake attendance. Howevernot all Android smartphone are equipped with ﬁngerprint scanner.\nMoreover, recording the user position through GPS on Android\ns"}
{"text": "he system recorded ﬁngerprint, attendance time,\nand the coordinate of position trough GPS that available on the\nsmartphone to avoid a long queue and fake attendance. Howevernot all Android smartphone are equipped with ﬁngerprint scanner.\nMoreover, recording the user position through GPS on Android\nsmartphone is inaccurate. According to Bauer (2013) GPS on\nAndroid smartphone had deviation about 10–93 m from the actual\nposition. Therefore, employees who are outside the ofﬁce but still\nclose enough to the ofﬁce can be recorded as present. Almost all\nproposed attendance systems based on ﬁngerprint recognition\ndid not report recognition accuracy except the system proposed\nbyZainal et al. (2016) , which is 85% with total recognition time\naround 7–9 min for 27 students. Moreover, there is a drawback\nin attendance system based on ﬁngerprint recognition. As reported\nbyZainal et al. (2016) , the system cannot recognize a ﬁngerprint if\nit is wet, dirty, or broken.\nChintalapati and Raghunadh (2013); Fuzail et al. (2014); Mehta\nand Tomar (2016); Raghuwanshi and Swami (2017); Sayeed et al.\n(2017); Wagh et al. (2015); Wati Mohamad Yusof et al., 2018 have\nproposed automated student attendance system based on face\nrecognition. The proposed systems were used a camera to capture\neither all student faces at once ( Fuzail, et al., 2014; Mehta and\nTomar, 2016; Raghuwanshi and Swami, 2017; Wagh, et al., 2015 )\nor one by one ( Chintalapati and Raghunadh, 2013; Sayeed, et al.,\n2017; Wati Mohamad Yusof et al., 2018 ).Chintalapati and\nRaghunadh (2013) used principle component analysis (PCA) and\nlocal binary pattern (LBP) combined with some classiﬁer to per-\nform face recognition and achieved the best classiﬁcation accuracy\nof 78% by using LBP and Euclidean distance for 80 students. Sayeed\net al. "}
{"text": "f et al., 2018 ).Chintalapati and\nRaghunadh (2013) used principle component analysis (PCA) and\nlocal binary pattern (LBP) combined with some classiﬁer to per-\nform face recognition and achieved the best classiﬁcation accuracy\nof 78% by using LBP and Euclidean distance for 80 students. Sayeed\net al. (2017) have proposed a real time face recognition using PCA\nand Euclidean distance for attendance system. Wati Mohamad\nYusof et al. (2018) have proposed a real time internet based atten-\ndance system using face recognition. The proposed system\nemployed Haar-cascade for face detection combined with LBP for\nface recognition. The systems proposed by Chintalapati and\nRaghunadh (2013); Sayeed et al. (2017); Wati Mohamad Yusofet al. (2018) are not efﬁcient since they only used a camera to cap-\nture student face image one by one. Fuzail et al. (2014); Wagh et al.\n(2015), Mehta and Tomar (2016) , and Raghuwanshi and Swami\n(2017) employed a camera to capture all students face in a class-\nroom at once. This strategy can avoid the occurrence of queues\nduring attendance process. However, the attendance systems that\nuse this strategy had a low accuracy on face recognition as\nreported by Raghuwanshi and Swami (2017) , that were 53.33%\nand 60% using principle component analysis (PCA) and Euclidean\ndistance and linear discriminant analysis (LDA), respectively.\nThe using of barcode ( Noor et al., 2015 ), QR code ( Rahni et al.,\n2015 ), RFID ( Arulogun et al., 2013; Bhalla et al., 2013; Hussain\net al., 2014; Rjeib et al., 2018 ), and NFC ( Mohandes, 2017 )i s\nanother alternative to record student identity in an attendance sys-\ntem. Attendance process in the systems proposed by Arulogun\net al. (2013); Bhalla et al. (2013); Hussain et al. (2014); Noor\net al. (2015); Rahni et al. (2015); Rjeib et"}
{"text": "l., 2014; Rjeib et al., 2018 ), and NFC ( Mohandes, 2017 )i s\nanother alternative to record student identity in an attendance sys-\ntem. Attendance process in the systems proposed by Arulogun\net al. (2013); Bhalla et al. (2013); Hussain et al. (2014); Noor\net al. (2015); Rahni et al. (2015); Rjeib et al. (2018) was very sim-\nple, students only needed to scan their student card contained bar-code, QR code, or RFID using the system to record attendance.\nWhile in NFC based attendance system ( Mohandes, 2017 ), students\nplaced their NFC phone near lecture’s NFC phone when entering\nclassroom. This process can lead to a long queue during attendance\nprocess. Fake attendance can also be occurred since student card\ncontained barcode, QR codes, or RFID and NFC phone are easily\ntransferable from one student to another. In addition, not all\nsmartphones are equipped with NFC systems. To overcome this\nproblem, the using of palm vein can be considered to recognize\nstudent in attendance system as proposed by Bayoumi et al.\n(2015) . However, not all cameras can be used to capture the image\nof palm vein. Furthermore, the accuracy of palm vein recognition in\nattendance system proposed in ( Bayoumi et al., 2015 ) was only\n78%. Therefore, from the current state of the art of automated\nattendance system it can be found that face recognition is the bestapproach to recognize student in an attendance system.\nCurrently, the number of Android smartphone is growing\nrapidly. Almost all students have at list an Android smartphone\nequipped with camera. According to Pratama (2017) , 95.24% of\nuniversity students in Indonesia have their own smartphone in\n2016. This phenomenon can be used to develop an attendance sys-\ntem using face recognition through Android smartphone. By imple-\nmenting such a system,"}
{"text": "st an Android smartphone\nequipped with camera. According to Pratama (2017) , 95.24% of\nuniversity students in Indonesia have their own smartphone in\n2016. This phenomenon can be used to develop an attendance sys-\ntem using face recognition through Android smartphone. By imple-\nmenting such a system, long queues occurred in previous\nautomated attendance process can be avoided. However, it is nec-\nessary to create a mechanism to ensure that every student really\nattend in the course. Furthermore, the accuracy of face recognition\nalso needs to be improved to guaranty the system can be imple-\nmented for several courses with a large number of students.\nThis paper proposed an attendance system using face recogni-\ntion by employing Android smartphone to capture student face.\nThe image was then sent to server for attendance process. Some\ninnovations have been performed in the proposed system. First,\nevery student only needed to capture his/her face image using\nhis/her Android smartphone to avoid a long queue. Second, in case\na student does not have a smartphone, the proposed system was\ndesigned such that the student who does not have a smartphone\ncan use other student’s smartphone to process his/her attendance.\nThird, the proposed system employed a simple classiﬁer to recog-\nnize student face. The last, to increase face recognition accuracy,\nthe proposed system only used a classiﬁer in a certain course.\nThe rest of the paper is organized as follow. Section 2 describes\nthe required materials and method used in the proposed atten-\ndance system. The experimental result and its analysis are pre-\nsented in Section 3 . Finally the conclusion is drawn in Section 4 .\n2. Materials and method\n2.1. Materials\nThe materials used to develop the proposed attendance system\nconsisted of hardware"}
{"text": "erials and method used in the proposed atten-\ndance system. The experimental result and its analysis are pre-\nsented in Section 3 . Finally the conclusion is drawn in Section 4 .\n2. Materials and method\n2.1. Materials\nThe materials used to develop the proposed attendance system\nconsisted of hardware, software, and face image data set. The hard-\nware was Android smartphone, Raspberry Pi, monitor, and com-\nputer server. The proposed attendance system required an\nAndroid smartphone 4.3 (Jelly Bean) or later with camera and\ninternet connection to open the attendance system by the lecturer\nand to process the student attendance. A Quad Core 1.2 GHz Broad-\ncom BCM2837 64bit and 1 GB RAM Raspberry Pi 3 Model B was\nused to get the course information from the server and displayed\nit to the monitor at front of classroom. A 3.60 GHz Intel(R) Core\n(TM) i7-7700 and 16 GB RAM computer with Ubuntu Linux version\n4.15.0-24-generic operating system was used as server.\nTwo Android applications were developed for the proposed\nattendance system, one for lecturer and one for student. The appli-\ncations were developed in Android Studio. The applications\nemployed Volley ( Developers, 2018 ), an HTTP library for Android,D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312 305\nand OpenCV ( Bradski, 2000 ), a computer vision library, for net-\nworking with the server and image processing, respectively. A\nweb client application was developed in PHP language to request\ninformation for opened attendance system by the Raspberry Pi\nfrom the server and to display the information on the monitor at\nthe front of classroom. On the server side, an application was also\ndeveloped in PHP language for communication with the Android\nsmartphone and the Raspberr"}
{"text": "nguage to request\ninformation for opened attendance system by the Raspberry Pi\nfrom the server and to display the information on the monitor at\nthe front of classroom. On the server side, an application was also\ndeveloped in PHP language for communication with the Android\nsmartphone and the Raspberry Pi. Moreover to carry out face\nrecognition and attendance processing tasks in the server, a python\nbased application was developed by employing OpenCV ( Bradski,\n2000 ) and Scikit-learn ( Pedregosa et al., 2011 ) libraries for image\nprocessing and face image classiﬁcation, respectively. All data used\nin the proposed attendance system were managed in the server\nusing MySQL. The proposed attendance system used two connec-\ntion types, Wi-Fi connection, to connect the Android smartphoneand the server, and LAN connection, to connect the Raspberry Pi\nto the server.\n2.2. Student registration\nEvery student in a course needed to register his/her face image\nand student registration number to the attendance system. The\nface image of every student was captured 10 times in the perpen-\ndicular direction to the smartphone camera with different expres-\nsion, including normal, smiling, laughing, and sad using a menu in\nthe Android application for student, as shown in Fig. 1 . Before cap-\nturing his/her face image, the student needed to make sure that\nhis/her face has been detected by the attendance system. The pro-posed attendance system employed Viola Jones algorithm ( Viola\nand Jones, 2004 ) to detect face area in the image. Once his/her face\ndetected the student was asked to capture his/her face image. The\nimage was captured in RGB color space and cropped into a\n224 /C2224 pixels such that the entire face is contained in the\nimage. The cropped image was stored in PNG format with a unique"}
{"text": " detect face area in the image. Once his/her face\ndetected the student was asked to capture his/her face image. The\nimage was captured in RGB color space and cropped into a\n224 /C2224 pixels such that the entire face is contained in the\nimage. The cropped image was stored in PNG format with a unique\nﬁle name related to student registration number. The image was\nthen uploaded to the server to build a face image data set. The ser-\nver is located in campus. This process was performed automati-\ncally by the proposed system without any intervention from the\nsystem administrator. The server is placed in campus and there\nis no one can access the face image database except the system\nand the system administrator. Therefore, the conﬁdentiality of\nthe face image database is really maintained.\nSome students captured his/her face images in a very low light-\ning intensity. Consequently, some face image had a very low inten-\nsity. Therefore such images were removed from the face imagedata set. Finally, the face image data set consisted of 4209 face\nimages was created and would be used to build a classiﬁer for face\nrecognition. The images were acquired from 423 students regis-\ntered at 21 courses. The number of students and face images in a\ncourse were between 19 and 30 and between 186 and 300, respec-\ntively. Fig. 2 shows the example of face images in the data set. The\nauthors have received permission from students whose face\nimages are used in his paper.\n2.3. Attendance process\nThe attendance process for the proposed attendance system\nconsisted of several steps starting from system opening, followed\nby QR code generation, face capturing, face recognition, and atten-\ndance processing. The architecture and global steps for the pro-\nposed attendance system are shown in Fig. 3 and the d"}
{"text": "ance process for the proposed attendance system\nconsisted of several steps starting from system opening, followed\nby QR code generation, face capturing, face recognition, and atten-\ndance processing. The architecture and global steps for the pro-\nposed attendance system are shown in Fig. 3 and the details are\nexplained as follow.\n2.3.1. System opening\nTo open the attendance system of a course, the lecturer of the\ncourse needed to enable the system through his/her Android\nsmartphone by choosing an appropriate course provided by the\nserver. The data of chosen course was sent to the server through\nhttp protocol. An Android application was developed to facilitate\nthe lecturer to take this step. From the application lecturer could\nalso cancel the class, change class schedule, and obtain student\nattendance report. The user interface for the application can be\nseen in Fig. 4 .\n2.3.2. QR code generation\nOnce the server received the information about the opening of\nattendance system for a certain course, the server generated QR\ncode contained information about course code, lecturer name,\nand schedule for the course using Simple QrCode ( https://www.\nsimplesoftware.io/docs/simple-qrcode ). Every minute the Rasp-\nberry Pi located in the classroom requested the status of atten-\ndance system for the course that will be conducted in the\nclassroom. If the attendance system has been opened by the lec-\nturer then the Raspberry Pi downloaded the generated QR code\nfrom server and displayed it to a monitor located at the front of\nclassroom. Fig. 5 shows the example of displayed QR code.\n2.3.3. Face capturing\nTo enter the opened course attendance system, a student\nneeded to capture the displayed QR code using the attendance sys-\nFig. 1. The application for student registration.306 D. Sunary"}
{"text": "o a monitor located at the front of\nclassroom. Fig. 5 shows the example of displayed QR code.\n2.3.3. Face capturing\nTo enter the opened course attendance system, a student\nneeded to capture the displayed QR code using the attendance sys-\nFig. 1. The application for student registration.306 D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312\ntem application installed in his/her own Android smartphone. This\nprocess was used to obtain the information of opened course and\nto make sure the student attend in the course. To minimize the\npossibility of cheating performed by students in attendance pro-\ncess, for example using QR code captured by other student, the sys-\ntem used campus intranet connection which is divided into several\nWi-Fi segments for communication between smartphones and ser-\nver. Therefore, the students who are not on Campus would not be\nable to process their attendance. The system used QRCodeScanner\n(https://github.com/blikoon/QRCodeScanner ), a QR scanning\nlibrary for Android, to scan displayed QR code. The student was\nthen asked to input his/her student registration number, and cap-\nture his/her face using the attendance system application. The\nimage was captured in RGB color space and stored in PNG format.\nIf the captured image contained a face then the image was cropped\ninto a 224 /C2224 pixels image such that the entire face is containedin the cropped image. To perform the cropping process, the Viola\nJones algorithm ( Viola and Jones, 2004 ) was also used to detect\nface region in the image. Fig. 6 shows the example of captured\nand cropped images. The cropped image, course information, and\nstudent registration number were then uploaded to server for face\nrecognition and attendance process.\n2.3.4. Fa"}
{"text": "es algorithm ( Viola and Jones, 2004 ) was also used to detect\nface region in the image. Fig. 6 shows the example of captured\nand cropped images. The cropped image, course information, and\nstudent registration number were then uploaded to server for face\nrecognition and attendance process.\n2.3.4. Face recognition\nIn the server, the cropped image was converted to grayscale\nimage and resized to a 96 /C296 pixels image. The grayscale value\nfor every pixel in the grayscale image was transformed into a\n9216 dimensional vector, as shown in Fig. 7 . This vector was used\nas input feature to a classiﬁer for face recognition. In this step, stu-\ndent registration number was used as class label or the target vari-\nable of classiﬁer. The proposed attendance system used some\nsimple classiﬁers for face recognition, including logistic regression\nFig. 2. The example of face image in the data set.\nFig. 3. The architecture and global steps for the proposed attendance system.D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312 307\n(LR), linear discriminant analysis (LDA), and k-nearest neighbor (k-\nNN). Such classiﬁer was chosen since it does not require a high\ncomputational cost and a high computer resource. Therefore the\nload of server was not too heavy either during classiﬁer training\nor during simultaneously accessed by many students for atten-\ndance processing.\n2.3.4.1. Logistic regression. Logistic regression is a simple binary\nclassiﬁer that can be extended to multiclass classiﬁer by imple-\nmenting the one versus the rest strategy. Logistic regressionassigns an unknown sample to a class Cithat has highest class pos-\nteriors distribution PC ijx;w;b ðÞ as in equation.\nPC ijx;w;b ðÞ ¼1\n1þe/C0yw0xþb ðÞ1\nwhere x¼x1;x2; :::;xn ðÞ is i"}
{"text": "er that can be extended to multiclass classiﬁer by imple-\nmenting the one versus the rest strategy. Logistic regressionassigns an unknown sample to a class Cithat has highest class pos-\nteriors distribution PC ijx;w;b ðÞ as in equation.\nPC ijx;w;b ðÞ ¼1\n1þe/C0yw0xþb ðÞ1\nwhere x¼x1;x2; :::;xn ðÞ is input feature, w;bðÞ is weight, and\ny2/C0 1;1 fg is the class label. The proposed system estimated weight\nw;bðÞ using the implementation of trust region Newton method ( Lin\net al., 2007 ) in LIBLINEAR library ( Fan et al., 2008 ) by minimizing a\ncost function deﬁned in equation.\nfw;bðÞ ¼1\n2w;b½/C1380w;b½/C138 þ CXl\ni¼1log 1 þe/C0yiw0xiþb ðÞ/C0/C1\n2\nwhere C>0 is a penalty parameter, yi2/C0 1;1 fg is class label,\nxi;i¼1;2; :::;l, is feature vector for training example, and lis the\nnumber of training example.\n2.3.4.2. Linear discriminant analysis (LDA). LDA perform classiﬁca-\ntion by determining linear decision boundaries that maximizing\nbetween-class scatter and minimizing within-class scatter. LDA\nassume that the class-conditional density of input feature\nx¼x1;x2; :::;xn ðÞ in class Ciis normal multivariate with mean li\nand covariance matrixPfor all i¼1;2; :::;k, as in equation.\nPxjCiðÞ ¼1\n2pðÞn=2Pjj1=2e/C01=2x/C0liðÞ0P\nx/C0liðÞ3\nBy using this assumption LDA assigns an unknown sample to a\nclass Ciif it has greatest linear discriminant value ( Hastie et al.,\n2009 ). The linear discriminant function of class Ciis calculated\nusing equation.\ndixðÞ ¼x0X/C01\nli/C01\n2l0\niX/C01\nliþlogpi 4\nwhere liis the prior probability of Ci.\n2.3.4.3. k-nearest neighbor (k-NN). k-NN classiﬁer assign an\nunknown sample to a class that has maximum number of exam-\nples close to the sample among kneighbors ( Alpaydin, 2014 ). In\nthe experiment, the proposed system used k¼1 and the distance\nbetween the sam"}
{"text": "ere liis the prior probability of Ci.\n2.3.4.3. k-nearest neighbor (k-NN). k-NN classiﬁer assign an\nunknown sample to a class that has maximum number of exam-\nples close to the sample among kneighbors ( Alpaydin, 2014 ). In\nthe experiment, the proposed system used k¼1 and the distance\nbetween the sample and its neighbors was measured using Eucli-\ndean distance as in equation.\nFig. 4. The application for lecturer.\nFig. 5. The example of displayed QR code.\nFig. 6. The example of captured and cropped image.308 D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312\ndx;xiðÞ ¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\nXn\nj¼1xj/C0xij/C0/C12vuut 5\nwhere x¼x1;x2; :::;xn ðÞ andxj¼xj1;xj2; :::;xjn/C0/C1\nare the feature vec-\ntors for the unknown sample and the jth neighbor j¼1;2; :::;k,\nrespectively, and nis the dimension of feature vector.\n2.3.5. Attendance processing\nIf student registration number resulted from step 4 match with\nstudent registration number inputted by student in step 3 then the\nstudent got a notiﬁcation from the attendance system that his/her\nattendance has been recorded. Otherwise, the student was asked to\ncapture his/her face once again. The result of attendance process\nwas then reported to lecturer through the attendance systemapplication installed in his/her Android smartphone, as shown in\nFig. 8 .\n2.4. Experimental setup\nAn experiment has been carried out in the laboratory to ﬁnd the\nbest classiﬁer in two training scenarios. The ﬁrst scenario, a classi-\nﬁer was used in attendance system for all courses. In this scenario\nall face image samples from all students registered at all courses\nwere used to train the classiﬁer. The second scenario, a classiﬁer\nwas only used in attendance system for a certain course. Therefore,\nif"}
{"text": "he ﬁrst scenario, a classi-\nﬁer was used in attendance system for all courses. In this scenario\nall face image samples from all students registered at all courses\nwere used to train the classiﬁer. The second scenario, a classiﬁer\nwas only used in attendance system for a certain course. Therefore,\nif there were ncourses, face image samples were divided into nsub\nsamples according to the list of course participants. Each sub sam-\nples was used to train the classiﬁer for attendance system in the\ncorresponding course. The result of this step was student registra-tion number related to the recognized image.\nTo validate the accuracy of the classiﬁer for face recognition, the\nproposed attendance system used stratiﬁed k-fold cross validation\nin the training and testing processes ( Alpaydin, 2014 ). The face\nimage data set was randomly divided into kmutually exclusive\nsubsets with equal size such that the number of face images in\nevery class has same proportion for all subsets. A subset was used\nas testing data and the remaining k/C01 subsets were used to train\nthe classiﬁer. The training and testing processes were repeated k\ntimes such that every subset is used as testing data on exactly once\niteration. Fig. 9 depicts the cross validation process.\nFor every testing data, the accuracy of the classiﬁer was calcu-\nlated using equation.\nAcc i¼cci\nNi/C2100% 6\nwhere Acc i;cciand Niare the accuracy of classiﬁer, the number of\ncorrectly classiﬁed sample, and the number of sample on ith testing\ndata, respectively. The average of Acc i;i¼1;2; :::;kwas calculated to\nobtain the ﬁnal accuracy for the classiﬁer. In this validation, the pro-\nposed attendance system used 2-fold and 5-fold cross validations to\nvalidate the accuracy of classiﬁer and to investigate the inﬂuence of\nincreasing the "}
{"text": "ng\ndata, respectively. The average of Acc i;i¼1;2; :::;kwas calculated to\nobtain the ﬁnal accuracy for the classiﬁer. In this validation, the pro-\nposed attendance system used 2-fold and 5-fold cross validations to\nvalidate the accuracy of classiﬁer and to investigate the inﬂuence of\nincreasing the number of sample in training data on classiﬁcation\naccuracy.\n3. Results and discussion\n3.1. First experimental scenario\nAs stated in section 2, in the ﬁrst experimental scenario all face\nimage data were used to train a classiﬁer for face recognition pro-\ncess. The classiﬁcation results for every classiﬁer with the ﬁrst\nFig. 7. The example of transformation (a) from cropped image into gray scale image and (b) from gray scale image (96x96) into gray scale vector (9216 /C21).\nFig. 8. The attendance report in lecturer’s application.D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312 309\nexperimental scenario are tabulated in Table 1 . As can be seen from\nTable 1 , LR produced higher classiﬁcation accuracy, which were\n93.22% and 95.21% for 2-fold and 5-fold cross validation respec-\ntively, compared to LDA (93.17% and 93.36%) and k-NN (86.06%and 88.37%). In 2-fold cross validation 50% image data set was used\nas training data, while in 5-fold cross validation used 80% image\ndata set. It can be observed in Table 1 that by increasing 30% train-\ning data, k-NN achieved the most signiﬁcant increasing in classiﬁ-\ncation accuracy (2.31%) followed by LR (1.99%) and LDA (0.19%).\nTherefore, it can be inferred that increasing the number of training\ndata would signiﬁcantly improve classiﬁcation accuracy for k-NN\nand LR.\nAlthough LR achieved the best classiﬁcation accuracy, it was not\nefﬁcient in term of computational time. As can be seen "}
{"text": "ollowed by LR (1.99%) and LDA (0.19%).\nTherefore, it can be inferred that increasing the number of training\ndata would signiﬁcantly improve classiﬁcation accuracy for k-NN\nand LR.\nAlthough LR achieved the best classiﬁcation accuracy, it was not\nefﬁcient in term of computational time. As can be seen in Table 1 ,\nin 2-fod and 5-fold cross validation LR required 1339.89 s and\n5143.99 s for training in the server, respectively, while LDA\nrequired only 27.80 s and 201.67 s. On the other hand, the classiﬁ-\ncation accuracy of LR was not signiﬁcantly different from LDA,\nwhich was only 0.05%. In this scenario, the server required about\n0.000190 s, 0.000179 s, and 0.033409 s to recognize a face image\nusing LR, LDA, and k-NN, respectively.\n3.2. Second experimental scenario\nIn the second experimental scenario face image data set was\npartitioned into 21 sub data sets according to the list of course par-\nticipant in 21 courses. The distribution of students and face images\nfor all courses are depicted in Fig. 10 . For classiﬁcation task, there\nwere 21 classiﬁers (one classiﬁer for one course) used by the pro-\nposed attendance system to perform face recognition. Each classi-\nﬁer was trained using the corresponding sub data set. Table 2\nsummarizes the classiﬁcation results for LR, LDA, and k-NN.\nAs can be seen from Table 2 , on average LR produced higher\nclassiﬁcation accuracy, which were 96.53% and 97.48% for 2-foldand 5-fold cross validations respectively, compared to LDA\n(95.24% and 97.29%) and k-NN (91.86% and 93.05%). This result\noutperforms the recognition accuracy in attendance systems pro-posed in ( Mohandes, 2017; Raghuwanshi and Swami, 2017;\nZainal, et al., 2016 ). In 2-fold cross validation, the numbers of clas-\nsiﬁer that achieved classiﬁcation accuracy greater than classiﬁc"}
{"text": ") and k-NN (91.86% and 93.05%). This result\noutperforms the recognition accuracy in attendance systems pro-posed in ( Mohandes, 2017; Raghuwanshi and Swami, 2017;\nZainal, et al., 2016 ). In 2-fold cross validation, the numbers of clas-\nsiﬁer that achieved classiﬁcation accuracy greater than classiﬁca-tion accuracy in the ﬁrst experimental scenario were 20, 16, and\n21 for LR, LDA, and k-NN, respectively. On the other hand, there\nwere 15, 18, and 14 for LR, LDA, and k-NN, respectively, in 5-fold\ncross validation. Furthermore, it can be seen in Table 2 that by\nincreasing 30% training data, on average LDA achieved the most\nsigniﬁcant increasing in classiﬁcation accuracy (2.05%) followed\nby k-NN (1.19%) and LR (0.95%). Therefore, it can be concluded that\nby using the second experimental scenario, the classiﬁcation per-\nformance could be improved about 2.07% until 5.80% both in 2-\nfold and 5-fold cross validations.\nIn the term of computational time, the second experimental\nscenario could reduce training time about 65.51% until 96.46% both\nin 2-fold and 5-fold cross validations, as shown in Table 2 . How-\never, LR still required more training time (48.98 s and 181.92 s)\ncompared to LDA (9.59 s and 42.52 s) and k-NN (5.36 s and\n7.42 s) both in 2-fold and 5-fold cross validations. In this scenario,\nthe server required about 0.000042 s, 0.000096 s, and 0,001683 s\nto recognize a face image sample using LR, LDA, and k-NN, respec-\ntively. Therefore, based on classiﬁcation accuracy and training\nFig. 9. k-fold cross validation process.\nTable 1\nThe classiﬁcation results for the ﬁrst experimental scenario.\nClassiﬁer 2-fold cross validation 5-fold cross validation\nAccuracy (%) Training time (s) Accuracy (%) Training time (s)\nLR 93.22 1339.89 95.21 5143.99\nLDA 93.17 27.80 93.36 201.67k-NN"}
{"text": "ining\nFig. 9. k-fold cross validation process.\nTable 1\nThe classiﬁcation results for the ﬁrst experimental scenario.\nClassiﬁer 2-fold cross validation 5-fold cross validation\nAccuracy (%) Training time (s) Accuracy (%) Training time (s)\nLR 93.22 1339.89 95.21 5143.99\nLDA 93.17 27.80 93.36 201.67k-NN 86.06 60.96 88.37 52.5991920 20 192019 19 19 2019201920 20 20 20 20 20 20 20 30186200199190194190190 189200186201189196200200 199198198198 200300\n050100150200250300350\nABCDEFGHI J KLM OPQRSTUV\nCourseThe number of student The number of face image\nFig. 10. The distribution of students and face image for all courses.310 D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312\ntime, the proposed attendance system employed LDA resulted\nfrom the second experimental scenario for face recognition step.\nFor further analysis the classiﬁcation result of LDA in the second\nexperimental scenario was divided into True Positive Rate (TPR),\nFalse Negative Rate (FNR), True Negative Rate (TNR) and False Pos-\nitive Rate (FPR), as summarized in Table 3 . As can be seen in\nTable 3 , LDA produced TPR and TNR of 97.44% and 99.87% on aver-\nage, respectively. It can be also seen in Table 3 , on average LDA\nachieved low FNR and FPR of 2.56% and 0.13%, respectively. This\nresults show that LDA could recognize the face of every student\nwith a good performance. Based on these results, the system has\nbeen implemented to process the attendance of 21 courses forthree semesters without any signiﬁcant problem.\n4. Conclusion\nThis paper proposes an Android based course attendance sys-\ntem using face recognition. The system asked every registered stu-\ndent to capture his/her face image and QR code displayed at the\nfront of classroom using his/her smartphone. The "}
{"text": "ree semesters without any signiﬁcant problem.\n4. Conclusion\nThis paper proposes an Android based course attendance sys-\ntem using face recognition. The system asked every registered stu-\ndent to capture his/her face image and QR code displayed at the\nfront of classroom using his/her smartphone. The captured image\nwas then uploaded to the server for face recognition and atten-\ndance process. To achieve a good face recognition accuracy and\nefﬁcient processing time, a classiﬁer was only used to perform face\nrecognition in a certain course. The experimental result shows that\nthe proposed attendance system achieved face recognition perfor-\nmance of 97.29% by employing LDA and only needed 0.000096 s for\nface recognition process in the server. For future work, the investi-\ngation of the using of Bluetooth devise for measuring the distance\nbetween student’s smartphone and Raspberry Pi located in class-\nroom, to ensure students attend in a course, will be consideredto minimize the possibility of cheating performed by students in\nattendance process.\nAcknowledgementsThe authors would like to thank Intitut Tehnologi Sepuluh Nopem-\nber Surabaya for providing facilities and ﬁnancial support under\nGrant no 1206/PKS/ITS/2018.\nDeclarations of interest\nNone.\nReferences\nAlpaydin, E., 2014. Introduction to Machine Learning. MIT press .\nArulogun, O., Olatunbosun, A., Fakolujo, O., Olaniyi, O., 2013. RFID-based students\nattendance management system. Int. J. Sci. Eng. Res. 4, 1–9 .\nBauer, C. 2013. On the (in-) accuracy of GPS measures of smartphones: a study of\nrunning tracking applications. In: Proceedings of International Conference on\nAdvances in Mobile Computing & Multimedia. pp. 335: ACM.\nBayoumi, S., Aldayel, A., Alotaibi, M., Aldraihem, M., Alrashed, S., Alzahrahi, S., 2015.\nClass atte"}
{"text": "On the (in-) accuracy of GPS measures of smartphones: a study of\nrunning tracking applications. In: Proceedings of International Conference on\nAdvances in Mobile Computing & Multimedia. pp. 335: ACM.\nBayoumi, S., Aldayel, A., Alotaibi, M., Aldraihem, M., Alrashed, S., Alzahrahi, S., 2015.\nClass attendance system based-on palm vein as biometric information. J.Theoret. Appl. Informat. Technol., 77\nBhalla, V., Singla, T., Gahlot, A., Gupta, V., 2013. Bluetooth based attendance\nmanagement system. Int. J. Innovat. Eng. Technol. (IJIET) 3, 227–233 .\nBradski, G. 2000. The Open CV Library. Dr. Dobb’s Journal: Software Tools for the\nProfessional Programmer, 25, pp. 120–123.\nChintalapati, S., Raghunadh, M. 2013. Automated attendance management system\nbased on face recognition algorithms. In: Computational Intelligence andComputing Research (ICCIC), 2013 IEEE International Conference on, IEEE. pp.\n1–5.\nDevelopers, A. 2018. Transmitting network data using Volley. In.\nFan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., Lin, C.-J., 2008. Liblinear: a library\nfor large linear classiﬁcation. J. Mach. Learn. Res. 9, 1871–1874 .\nFuzail, M., Nouman, H.M.F., Mushtaq, M.O., Raza, B., Tayyab, A., Talib, M.W., 2014.\nFace detection system for attendance of class’ students. Int. J. Multidiscipl. Sci.\nEng., 5\nHastie, T., Tibshirani, R., Friedman, J., 2009. The Elements of Statistical Learning New\nYork. Springer, NY .\nHussain, E., Dugar, P., Deka, V., Hannan, A. 2014. RFID based student attendance\nsystem. In: National Conference cum Workshop on Bioinformatics andComputational Biology. Citeseer. pp. 30–32.\nIslam, M. M., Hasan, M. K., Billah, M. M., Uddin, M. M. 2017. Development of\nsmartphone-based student attendance system. In: 2017 IEEE Region 10\nHumanitarian Technology Conference (R10-HTC). pp"}
{"text": "tem. In: National Conference cum Workshop on Bioinformatics andComputational Biology. Citeseer. pp. 30–32.\nIslam, M. M., Hasan, M. K., Billah, M. M., Uddin, M. M. 2017. Development of\nsmartphone-based student attendance system. In: 2017 IEEE Region 10\nHumanitarian Technology Conference (R10-HTC). pp. 230–233.\nLin, C.-J., Weng, R.C., Keerthi, S.S. 2007. Trust region newton methods for large-scale\nlogistic regression. In: Proceedings of the 24th international conference on\nMachine learning. ACM pp. 561–568.\nMehta, P., Tomar, P., 2016. An efﬁcient attendance management sytem based on\nface recognition using Matlab and Raspberry Pi 2. Int. J. Eng. Technol. Sci. Res., 3\nMohamed, B. K. P., Raghu, C. V. 2012. Fingerprint attendance system for classroom\nneeds. In: 2012 Annual IEEE India Conference (INDICON). pp. 433–438.\nMohandes, M.A., 2017. Class attendance management system using NFC mobile\ndevices. Intell. Automat. Soft Comput. 23, 251–259 .\nNoor, S.A.M., Zaini, N., Latip, M.F.A., Hamzah, N. 2015. Android-based attendance\nmanagement system. In: 2015 IEEE Conference on Systems, Process and Control\n(ICSPC) (pp. 118–122).\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel,\nM., Prettenhofer, P., Weiss, R., Dubourg, V., 2011. Scikit-learn: machine learning\nin Python. J. Mach. Learn. Res. 12, 2825–2830 .\nPratama, A.R., 2017. Exploring Personal Computing Devices Ownership Among\nUniversity Students in Indonesia. Springer International Publishing, Cham, pp.\n835–841 .\nRaghuwanshi, A., Swami, P. D. 2017. An automated classroom attendance system\nusing video based face recognition. In: Recent Trends in Electronics, Information& Communication Technology (RTEICT), 2017 2nd IEEE International\nConference on: IEEE. pp. 719–724.Table 2\nClassiﬁcation result"}
{"text": ", pp.\n835–841 .\nRaghuwanshi, A., Swami, P. D. 2017. An automated classroom attendance system\nusing video based face recognition. In: Recent Trends in Electronics, Information& Communication Technology (RTEICT), 2017 2nd IEEE International\nConference on: IEEE. pp. 719–724.Table 2\nClassiﬁcation results for the second experimental scenario.\nClassiﬁer The number of classiﬁer 2-fold cross validation 5-fold cross validation\nAverage accuracy (%) Total training time (s) Average accuracy (%) Total training time (s)\nLR 21 96.53 48.98 97.48 181.92\nLDA 21 95.24 9.59 97.29 42.52k-NN 21 91.86 5.36 93.05 7.42\nTable 3\nTPR, FNR, TNR, and FPR for LDA in the second experimental scenario.\nCourse TPR (%) FNR (%) TNR (%) FPR (%)\nA 95.16 4.84 99.73 0.27\nB 98.00 2.00 99.89 0.11C 98.99 1.01 99.95 0.05D 97.37 2.63 99.85 0.15E 96.39 3.61 99.81 0.19F 97.89 2.11 99.88 0.12G 94.74 5.26 99.71 0.29\nH 97.35 2.65 99.85 0.15\nI 98.50 1.50 99.92 0.08J 95.70 4.30 99.76 0.24K 97.51 2.49 99.87 0.13L 97.88 2.12 99.88 0.12M 99.65 0.35 99.98 0.02O 97.50 2.50 99.87 0.13\nP 96.50 3.50 99.82 0.18\nQ 95.98 4.02 99.79 0.21R 98.48 1.52 99.92 0.08S 100.00 0.00 100.00 0.00T 98.99 1.01 99.95 0.05U 98.00 2.00 99.89 0.11V 95.67 4.33 99.85 0.15Average 97.44 2.56 99.87 0.13D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312 311\nRahni, A., Zainal, N., Adna, M.Z., Othman, N., Bukhori, M., 2015. Development of the\nonline student attendance monitoring system (SAMSTM) based on QR-codes\nand mobile devices. J. Eng. Sci. Technol. 10, 28–40 .\nRao, S., Satoa, K., 2013. An attendance monitoring system using biometrics\nauthentication. Int. J. Adv. Res. Comput. Sci. Softw. Eng., 3\nRjeib, H.D., Ali, N.S., Al Farawn, A., Al-Sadawi, B., Alsharqi, H., 2018. Attendance and\ninformation syst"}
{"text": "des\nand mobile devices. J. Eng. Sci. Technol. 10, 28–40 .\nRao, S., Satoa, K., 2013. An attendance monitoring system using biometrics\nauthentication. Int. J. Adv. Res. Comput. Sci. Softw. Eng., 3\nRjeib, H.D., Ali, N.S., Al Farawn, A., Al-Sadawi, B., Alsharqi, H., 2018. Attendance and\ninformation system using RFID and web-based application for academic sector.\nInt. J. Adv. Comput. Sci. Appl. (IJACSA), 9 .\nSayeed, S., Hossen, J., Kalaiarasi, S., Jayakumar, V., Yusof, I., Samraj, A., 2017. Real-\ntime face recognition for attendance monitoring system. J. Theoret. Appl.\nInformat. Technol. 95 .\nSoewito, B., Gaol, F. L., Simanjuntak, E., Gunawan, F. E. 2015. Attendance system on\nAndroid smartphone. In: 2015 International Conference on Control, Electronics,\nRenewable Energy and Communications (ICCEREC) pp. 208–211.\nViola, P., Jones, M.J., 2004. Robust real-time face detection. Int. J. Comput. Vision 57,\n137–154 .Wagh, P., Thakare, R., Chaudhari, J., Patil, S. 2015. Attendance system based on face\nrecognition using eigen face and PCA algorithms. In: Green Computing and\nInternet of Things (ICGCIoT), 2015 International Conference on: IEEE pp. 303–\n308.\nWati Mohamad Yusof, Y., Asyraf Mohd Nasir, M., Azura Othman, K., Izwan Suliman,\nS., Shahbudin, S., Mohamad, R., 2018. Real-time internet based attendance usingface recognition system. Int. J. Eng. Technol. 7 (3.15). Special Issue 15\n.\nZainal, N.I., Sidek, K.A., Gunawan, T.S., 2016. Portable anti forgery recognition for\nattendance system using ﬁngerprint based biometric. ARPN J. Eng. Appl. Sci. 11,\n396–403 .\nZainal, N. I., Sidek, K. A., Gunawan, T. S., Manser, H., Kartiwi, M. 2014. Design and\ndevelopment of portable classroom attendance system based on Arduino and\nﬁngerprint Biometric. In: Information and Communication Technology for "}
{"text": "ing ﬁngerprint based biometric. ARPN J. Eng. Appl. Sci. 11,\n396–403 .\nZainal, N. I., Sidek, K. A., Gunawan, T. S., Manser, H., Kartiwi, M. 2014. Design and\ndevelopment of portable classroom attendance system based on Arduino and\nﬁngerprint Biometric. In: Information and Communication Technology for The\nMuslim World (ICT4M), 2014 The 5th International Conference on: IEEE. pp. 1–4.312 D. Sunaryono et al. / Journal of King Saud University – Computer and Information Sciences 33 (2021) 304–312"}
